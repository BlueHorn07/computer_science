---
title: "Statistical Data Mining"
layout: post
use_math: true
tags: ["Statistical Data Mining"]
hidden: true
---

<br/>

2021-1í•™ê¸°ì— ìˆ˜ê°•í•œ ì±„ë¯¼ìš° êµìˆ˜ë‹˜ì˜ "**í†µê³„ì  ë°ì´í„° ë§ˆì´ë‹(IMEN472)**" ìˆ˜ì—…ì—ì„œ ë°°ìš´ ê²ƒê³¼ ê³µë¶€í•œ ê²ƒì„ ì •ë¦¬í•œ ì§€í‚¬ ë¸”ë¡œê·¸ì…ë‹ˆë‹¤. ê°œì¸ì ìœ¼ë¡œ ë³¸ì¸ì´ ì²˜ìŒ ë„ì „í•´ë³´ëŠ” ë¶„ì•¼ê³  ì‘ìš© ìˆ˜í•™ì˜ ìˆ˜ë§ì€ í…Œí¬ë‹‰ë“¤ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ìˆ˜ì—…ì„ ë”°ë¼ê°€ëŠ”ê²Œ ì‰½ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤ë§Œ, ë³¸ ìˆ˜ì—…ì„ í†µí•´ì„œ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì— ëŒ€í•œ í”„ë¡ í‹°ì–´ë¥¼ ë§›ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ğŸ¤¯

#### ì°¸ê³  êµì¬
- [ã€The Elements of Statistical Learningã€](https://web.stanford.edu/~hastie/ElemStatLearn/) Trevor Hastie Â· Robert Tibshirani Â· Jerome Friedman, 2nd ed.
- [ã€An Introduction to Statistical Learningã€](https://www.statlearning.com/) Gareth James Â· Daniela Witten Â· Trevor Hastie Â· Robert Tibshirani, 1st ed.
- [CS229: Machine Learning](http://cs229.stanford.edu/syllabus-autumn2018.html), Andrew Ng, Stanford Univ. [^1]

<div class="math-statement" markdown="1" style="padding: 10px 20px">

[ëª©ì°¨]

1. Supplemnetary
2. Introduction
3. Linear Regression
4. Linear Classification
5. Non-parametric Method
6. Decision Tree
7. Boosting ğŸ”¥
8. Random Forest ğŸ”¥
9. SVM; Support Vector Machine
10. PCA; Principle Component Analysis ğŸ”¥
11. Clustering

</div>

<hr/>

### Supplementary

ì•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” "í†µë°ë§ˆ"ì˜ ì‹¤ì „ì„ ë§ˆì£¼í•˜ê¸° ì „ì— "**ë°˜ë“œì‹œ**" ì•Œì•„ì•¼ í•˜ëŠ” ë‚´ìš©ë“¤ì…ë‹ˆë‹¤. ëª¨ë“  ë‚´ìš©ê³¼ ìˆ˜í•™ì  í‘œí˜„ê³¼ ì¶”ìƒí™”ì— ì¶©ë¶„íˆ ìµìˆ™í•´ì ¸ì•¼ í•©ë‹ˆë‹¤.

<details markdown="1" class="statement">
<summary>í¼ì³ë³´ê¸°</summary>

#### Linear Algebra

- [Basic Linear Algebra]({{"/2021/03/07/supp-1-linear-algebra-1.html" | relative_url}})
  - Column space & Row space & Null space
  - Fundamental Theorem of Linear Algebra
  - Eigen value & Eigen vector 

- [Vector Calculus & Matrix Calculus]({{"/2021/03/08/supp-1-linear-algebra-2.html#matrix-calculus" | relative_url}})
- [Spectral Decomposition & Singular Value Decomposition]({{"/2021/03/14/supp-1-linear-algebra-3.html" | relative_url}})

#### Multivariate Normal Distribution

#### Conditional Expectation

</details>

<hr/>

### [Introduction]({{"/2021/02/26/overview-of-supervised-learning.html" | relative_url}})

- Introduction to Regression & Classification
  - Least Squared Method
  - Nearest Neighbor Method
- Curse of dimentionality

<hr/>

### Linear Methods for Regression

- [Feature Selection]({{"/2021/05/16/feature-selection-techniques.html" | relative_url}})
  - Best Subset Selection
  - Forward Stepwise Selection
  - Backward Stepwise Selection
  - Mallow's $C_p$
  - AIC & BIC
  - Instability of Variable Selection

- Shrinkage Method

- Lasso Regression
- Ridge Regression

<hr/>

### Non-parametric Method

- [Non-parametric Linear Regression]({{"/2021/04/18/regression-spline.html" | relative_url}})
  - Polynomial Regression
    - Local Polynomical Regression
  - [Regression Spline]({{"/2021/04/18/regression-spline.html#regression-spine" | relative_url}}) ğŸ”¥
  - Natural Cubic Spline
    - power basis function
  - Smoothing Splines
    - knot selection
  - [Non-parametric Logistic Regression]({{"/2021/04/19/splines-method-2.html#non-parameteric-logistic-regression" | relative_url}})
  - [Multi-dimensional Splines]({{"/2021/04/19/splines-method-2.html#multi-dimensional-splines" | relative_url}})

- [KNN Method]({{"/2021/05/16/KNN-and-kernel-method.html" | relative_url}})
  - [kernel method]({{"/2021/05/16/KNN-and-kernel-method.html#kernel-method" | relative_url}})
- Nadaraya-Watson Estimator

- Additive Model
- Backfitting Algorithm
- Generalized Additive Models ğŸ”¥
- MARS; Multivariate Adaptive Regression Spline ğŸ”¥


<hr/>

### Boosting

- AdaBoost
- Gradient Boosting
- XGBoost

### Random Forest



<hr/>

[^1]: ìˆ˜ì—…ì˜ ì¼ë¶€ í† í”½ì—ì„œ CS229ì—ì„œ ë°°ìš´ ë¶€ë¶„ì´ ì¢…ì¢… ë“±ì¥í–ˆìŠµë‹ˆë‹¤. CS229ì—ì„œ í†µê³„ì  ì ‘ê·¼ì„ í†µí•´ ê³ ì „ì ì¸ ë¨¸ì‹  ëŸ¬ë‹ì„ ë‹¤ë£¨ê¸° ë•Œë¬¸ì— ë‘ ê³¼ëª©ì„ ê³µë¶€í•˜ëŠ” ë°ì— ì–‘ë°©í–¥ìœ¼ë¡œ ë„ì›€ì„ ë§ì´ ë°›ì•˜ìŠµë‹ˆë‹¤ ğŸ˜Š


