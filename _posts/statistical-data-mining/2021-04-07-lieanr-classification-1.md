---
title: "Linear Classification - 1"
layout: post
use_math: true
tags: ["Statistical Data Mining"]
# hidden: true
---

### ì„œë¡ 
2021-1í•™ê¸°, ëŒ€í•™ì—ì„œ 'í†µê³„ì  ë°ì´í„°ë§ˆì´ë‹' ìˆ˜ì—…ì„ ë“£ê³  ê³µë¶€í•œ ë°”ë¥¼ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- Classification by Linear Regression
  - Binray Classification
  - Multi-class Classification
- Probabilistic Model
- Linear Discriminant Analysis

<hr/>

## Classficiation by Linear Regression

### Binray Classification

Assume that $\mathcal{Y}= \\{ 0, 1 \\}$, and consider the \<linear regression\> model

$$
Y = X^T \beta + \epsilon
$$

For some estimator $\hat{\beta}$, and given $X=x$, predictor $Y$ do something like this

$$
\hat{Y} = \begin{cases}
  \quad 1 & \text{if } x^{T}\hat{\beta} > 0.5 \\
  \quad 0 & \text{if } x^{T}\hat{\beta} \le 0.5
\end{cases}
$$

ì´ë•Œ, $x^T \hat{\beta}$ëŠ” $Y=1$ì— ëŒ€í•œ í™•ë¥ ì„ ë±‰ëŠ” í•¨ìˆ˜ì˜ ì¼ì¢…ì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.

$$
\hat{f}(x) = \text{Pr}(Y = 1 \mid X = x) = E(Y \mid X = x)
$$

ì´ë ¨ í˜•íƒœì˜ ê° Classì— ëŒ€í•œ posterior probabilityë¥¼ ê³„ì‚°í•´ Classifyë¥¼ ì§„í–‰í•˜ëŠ” ëª¨ë¸ì„ \<**Bayes Classifier**\>ë¼ê³  í†µì¹­í•œë‹¤.

### Multi-class Classification

Assume that $\mathcal{Y}=\\{1, \dots, K\\}$, and let $\mathbf{Y}$ be the $n \times K$ binray matrix where the $(i, k)$ element is $1$ if $y_i = k$ and $0$ otherwise.

Let 

$$
\hat{\mathbf{B}} = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T\mathbf{Y}
$$

(deriven from RSS estimator!)

$$
\hat{\mathbf{Y}} = \mathbf{X} \hat{\mathbf{B}}
$$

ì´ë ‡ê²Œ ë‘”ë‹¤ë©´ inferenceì—ì„œëŠ”, For $X=x$, one may predict $Y$ as

$$
\hat{Y} = \underset{k\in\mathcal{Y}}{\text{argmax}} \; {\hat{f}_k (x)}
$$

where $(\hat{f}_1 (x), \dots, \hat{f}_K(x)) = x^T \hat{\mathbf{B}}$.

ì´ë•Œ, ê° $\hat{f}_i (x)$ëŠ” binray classificationì˜ $\hat{f}(x)$ì™€ ë¹„ìŠ·í•˜ê²Œ ì•„ë˜ì˜ ì¡°ê±´ë¶€ í™•ë¥  ë˜ëŠ” poster-priorityë¥¼ ì˜ˆì¸¡í•˜ëŠ” estimatorì˜ ì—­í• ì„ í•œë‹¤.

$$
\hat{f}_k (x) = \text{Pr}(Y=k \mid X=x)
$$

<br/>

<span class="statement-title">Problem.</span><br>


(ì¶”í›„ì— ê¸°ìˆ )

<hr/>

## Probabilistic Model

ìœ„ì˜ ë‘ ê²½ìš°ì—ì„œ ì‚´í´ë´¤ë“¯, Linear Regressionì— ì˜í•œ ì ‘ê·¼ì€ ê²°êµ­ ì•„ë˜ì˜ ì¡°ê±´ë¶€ í™•ë¥ ì„ estimate í•˜ëŠ” ì ‘ê·¼ì´ì—ˆë‹¤.

$$
\text{Pr}(Y=k \mid X=x)
$$

ì´ë•Œ, ì´ ì¡°ê±´ë¶€ í™•ë¥ ì€ posterior probabilityë¡œ \<ë² ì´ì¦ˆ ì •ë¦¬\>ì— ì˜í•´ ì•„ë˜ì™€ ê°™ë‹¤.

$$
\text{Pr}(Y=k \mid X=x) = \frac{\pi_k \cdot f_k(x)}{\displaystyle \sum^K_{i=1} \pi_i \cdot f_i (x)}
$$

ì´ë•Œ, ìš°ë³€ì˜ ê° í•­ëª©ë“¤ì„ ì‚´í´ë³´ë©´

- $\pi_k$: the \<**class probability**\> of class $k$; prior probability

$$
\pi_k = P(y=k)
$$

- $f_k (x)$: the \<**class-conditional density**\> of $X$ in class $Y=k$

$$
f_k (x) = P(X=x \mid Y=k)
$$

ë§Œì•½ ìš°ë¦¬ê°€ $\pi_k$, $f_k (x)$ë¥¼ ëª¨ë‘ ì•Œê³  ìˆë‹¤ë©´, ìš°ë¦¬ëŠ” $X=x$ê°€ ìˆì„ ë•Œ, ì–´ë–¤ $Y=k$ê°€ ì„ íƒë˜ì–´ì•¼ í•˜ëŠ”ì§€ estimate í•  ìˆ˜ ìˆë‹¤. ë‹¨, $\pi_k$, $f_k(x)$ëŠ” ëª¨ë‘ ìš°ë¦¬ê°€ ì¶”ì •í•´ì•¼ í•˜ëŠ” ê°’ì´ë©°, ì´ê²ƒì„ ì¶”ì •í•˜ê¸° ìœ„í•´ ì–´ë–»ê²Œ ì ‘ê·¼í•˜ê³  ì–´ë–¤ ê°€ì •ì„ ì“°ëŠ”ì§€ ìˆ˜ì—…ì—ì„œ ë°°ìš´ë‹¤.

## Linear Discriminant Analysis

LDAëŠ” $f_k$ê°€ ì•„ë˜ì™€ ê°™ì€ ì •ê·œ ë¶„í¬ $N(\mu_k, \Sigma_k)$ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•œë‹¤. [^1]

$$
f_k(x) = \frac{1}{\left| 2\pi \Sigma_k \right|^{1/2}} \exp \left[ - \frac{(x-\mu_k)^T \Sigma_k^{-1} (x-\mu_k)}{2}\right]
$$

ì´ë•Œ, ë§Œì•½ ê° $\Sigma_k$ì— ëŒ€í•´ 

$$
\Sigma_k = \Sigma \quad \text{for all} \; k
$$

ë¼ëŠ” ì•„ì£¼ì•„ì£¼ íŠ¹ë³„í•œ ê°€ì •ì´ ì¶”ê°€ëœ ê²ƒì´ \<**LDA; Linear Discriminant Analysis**\>ë‹¤! ğŸ˜

<br/>

ìœ„ì™€ ê°™ì´ ì„¤ì •í–ˆì„ ë•Œì˜ \<decision boundary\>ë¥¼ ìƒê°í•´ë³´ì.

$$
P(Y=k \mid X=x) = P(Y=l \mid X=x)
$$

boundaryì— ëŒ€í•œ ìœ„ì˜ ì‹ì„ ì˜ ì •ë¦¬í•´ë³´ë©´,

$$
\begin{aligned}
\log \frac{P(Y=k \mid X=x)}{P(Y=l \mid X=x)} &= \log \frac{\pi_k \cdot f_k(x)}{\pi_l \cdot f_l(x)} = \log \frac{\pi_k}{\pi_l} + \log \frac{f_k(x)}{f_l(x)} \\
&= \log \frac{\pi_k \cdot f_k(x)}{\pi_l \cdot f_l(x)} + \log \left( \frac{\exp\left( -\frac{(x-\mu_k)^T\Sigma^{-1}(x-\mu_k)}{2}\right)}{\exp\left( -\frac{(x-\mu_l)^T\Sigma^{-1}(x-\mu_l)}{2}\right)}\right) \\
&= \log \frac{\pi_k \cdot f_k(x)}{\pi_l \cdot f_l(x)} + \log \left( \exp \left( - \frac{}{2}\right) \right)
\end{aligned}
$$

<hr/>

[^1]: ê°•ì¡°í•˜ì§€ë§Œ, ë°˜ë“œì‹œ ì´ë ‡ê²Œ ëª¨ë¸ë§í•  ìˆ˜ ìˆëŠ” ê±´ ì•„ë‹ˆë‹¤. $f_k(X)$ì˜ ë¶„í¬ê°€ $N(\mu_k, \Sigma_k)$ë¥¼ ë”°ë¥¸ë‹¤ê³  'ê°€ì •'í–ˆì„ ë¿ì´ë‹¤! ì‹¤ì œ $f_k(X)$ì˜ ë¶„í¬ëŠ” ë‹¤ë¥¼ ê°€ëŠ¥ì„±ì´ í¬ë‹¤!