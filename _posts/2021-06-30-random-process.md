---
title: "Random Process"
layout: post
use_math: true
tags: ["Machine Learning"]
---

### ì„œë¡ 

"Machine Learning"ì„ ê³µë¶€í•˜ë©´ì„œ ê°œì¸ì ì¸ ìš©ë„ë¡œ ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<hr/>

ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” "í™•ë¥ ë¡ (Probability Theory)"ê³¼ "Machine LEarning"ì„ ê³µë¶€í•  ë•Œ ë“±ì¥í•˜ëŠ” *"Process"* ê°€ ë¶™ì€ ëª¨ë“  ê°œë…ì„ ë„“ì€ ì‹œì•¼ë¡œ ì‚´í´ë³´ê¸° ìœ„í•´ ì‘ì„±í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‹¤ë£¨ëŠ” ì£¼ì œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

- Random Process; Stochastic Process
- Bernoulli Process
- Poisson Process
- Gaussian Process
- Markov Process

<hr/>

## Introduction to Random Process

<div class="definition" markdown="1">

<span class="statement-title">Definition.</span> Random Process<br>

A **random process** is a time-varing function, that assigns the outcome of a random experiment to each time instant.

</div>

ëŒ€ì¶©, (time instant)ì— random experimentì˜ ê²°ê³¼(outcome)ì„ ë§¤í•‘í•œë‹¤ëŠ” ëœ»ì´ë‹¤.

ë˜ëŠ” ì•„ë˜ì™€ ê°™ì´ ì •ì˜í•˜ê¸°ë„ í•˜ëŠ”ë°,

<div class="definition" markdown="1">

A (infinite) sequence of random variables $X_1, X_2, \dots, X_n, \dots$

</div>

ì¦‰, RVì˜ infinite sequenceë¥¼ \<**random process**\>ë¼ê³  í•œë‹¤. ì²«ë²ˆì§¸ ì •ì˜ë³´ë‹¤ëŠ” ë‘ë²ˆì§¸ ì •ì˜ê°€ ì¢€ë” ì™€ë‹¿ëŠ” í¸ì´ë‹¤. ğŸ‘

\<random process\>ë¥¼ ì •ì˜í•  ë•Œ, RV $X_i$ê°€ ë“±ì¥í–ˆìœ¼ë‹ˆ ìì—°ìŠ¤ëŸ½ê²Œ ì•„ë˜ì˜ ì„±ì§ˆë“¤ì„ ê°€ì§ˆ ê²ƒì´ë‹¤.

- $E[X_i]$: mean of RV
- $\text{Var}(X_i)$: variance of RV
- $p_{X_i} (x_i)$: marginal probability distribution of RV

ìš°ë¦¬ëŠ” \<random process\> ìì²´ì˜ ë¶„í¬ë¥¼ ìƒê°í•´ë³¼ ìˆ˜ë„ ìˆëŠ”ë°, ì´ê²ƒì€ ì•„ë˜ì™€ ê°™ì€ joint probability distributionì´ ëœë‹¤.

$$
p_{X_1, \dots, X_n, \dots} (x_1, \dots, x_n, \dots)
$$

ë˜, ìš°ë¦¬ëŠ” \<random process\>ì˜ Sample Space $\Omega$ì— ëŒ€í•´ ìƒê°í•´ë³¼ ìˆ˜ ìˆë‹¤.

\<random process\> ì¤‘ í•˜ë‚˜ì¸ \<Bernoulli Process\>ì˜ ê²½ìš°, Sample SapceëŠ” 0-1ì˜ infinite sequenceê°€ ëœë‹¤.

<div class="theorem" markdown="1">

<span class="statement-title">Property.</span> Sample Space of Bernoulli Process<br>

$$
\Omega_{\text{BP}} 
= \left\{ 
  (b_1, \dots, b_n, \dots ) \mid b_i \in \{ 0, 1 \}
  \right\}
$$

</div>

\<Bernoullid Process\>ì˜ ê²½ìš°, Sample Space $\Omega$ì—ì„œ ì–´ë–¤ subsetì„ ì·¨í•˜ëŠ”ì§€ì— ë”°ë¼ ëª‡ê°€ì§€ Discrete Distributionë“¤ì„ ìœ ë„í•´ë³¼ ìˆ˜ ìˆë‹¤! ğŸ˜ í•´ë‹¹ ë‚´ìš©ì€ ì•„ë˜ì—ì„œ \<Bernoulli Process\>ë¥¼ ë‹¤ë£° ë•Œ, ì¢€ë” ì†Œê°œí•˜ê² ë‹¤.

<hr/>

### Some Properties of Random Process

\<Random Process\>ëŠ” ì•„ë˜ì™€ ê°™ì€ ëª‡ê°€ì§€ íŠ¹ì§•ì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤. <span style="color: red">ì´ê²ƒì€ í•„ìˆ˜ì ì¸ ê²ƒì€ ì•„ë‹ˆë©°, ëª‡ëª‡ \<random process\>ì— ê³µí†µì ìœ¼ë¡œ ë³´ì´ëŠ” íŠ¹ì§•ì´ê±°ë‚˜ ê°€ì •ì´ë‹¤.</span>

<big>**1. Independence btw trials**</big>

ê°œë³„ trialsì€ ì„œë¡œ ë…ë¦½ì ìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤. ì¦‰, ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤.

- Bernoulli Process, Poisson Process, ...

<big>**2. Memoeryless Property**</big>

$$
P(X = x + k \mid x > k) = P(X = x)
$$

- Bernoulli Process, Poisson Process, ...
- Markov Process

<hr/>

### Bernoulli Process (2)

ì´ í¬ìŠ¤íŠ¸ëŠ” \<[Bernoulli Process](https://bluehorn07.github.io/mathematics/2021/03/25/poisson-distribution.html#bernoulli-process)\>ì— ëŒ€í•œ ë‚´ìš©ì—ì„œ ì¶”ê°€ì ì¸ ì£¼ì œë“¤ì„ ë‹¤ë£¬ë‹¤. ì•„ì§ \<Bernoulli Processs\>ê°€ ë­”ì§€ ëª¨ë¥¸ë‹¤ë©´, ìœ„ì˜ í¬ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì½ì–´ë³´ì!

<div class="theorem" markdown="1">

<big>1. Number of Success $S_n$ in $n$ trials.</big>

Let's derive a random variable $S_n = X_1 + \cdots + X_n$ from the Bernoulli Process.

Then, $S_n$ follows the \<Binomial Distribution\>!

$$
P(S_n = x) = \binom{n}{x} p^x (1-p)^{n-x} \quad \text{for} \; x=0, 1, \dots, n
$$

</div>

<div class="theorem" markdown="1">

<big>2. Time until the first success</big>

Let's derive a randome variable $T_1 = \min \\{ i \in \mathbb{N} : X_i = 1\\}$ from the Bernoulli Process.

Then, $T_1$ follows the \<Geometric Distribution\>!

$$
P(T_1 = x) = P(\underbrace{0, 0, \dots, 0}_{x-1}, 1) = (1-p)^{x-1} p \quad \text{for} \; x=1, 2, \dots
$$

</div>

<div class="theorem" markdown="1">

<big>3. Time until the first $k$ success</big>

\<Geometric Random Variable\>ì¸ $T_1$ì„ í™•ì¥í•œ ê°œë…ì´ë‹¤. 

Let's derive a randome variable $T_k = \min \\{ i \in \mathbb{N} : \| \\{ X_i : X_i = 1 \\} \| = k\\}$ from the Bernoulli Process.

Then, $T_n$ follows the \<Negative Binomial Distribution\>!

$$
P(T_k = x) = P(\underbrace{0, 1, \dots, 1, \dots, 0}_{k-1 \text{ success}}, 1) = \binom{x-1}{k-1} (1-p)^{x-k} p^k \quad \text{for} \; x=k, k+1, \dots
$$

</div>

<hr/>

### Poisson Process

ì•„ë˜ í¬ìŠ¤íŠ¸ì˜ ë‚´ìš©ìœ¼ë¡œ ëŒ€ì²´

ğŸ‘‰ [Poisson Process](https://bluehorn07.github.io/mathematics/2021/03/25/poisson-distribution.html#poisson-process)

<hr/>

### Gaussian Process

ì¶”í›„ ì‘ì„± ì˜ˆì •

<hr/>

### Markov Process

ì¶”í›„ ì‘ì„± ì˜ˆì •

<hr/>

### references

- [[MIT OCW] Introduction to Probability: Lecture 21](https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-iii-random-processes/MITRES_6_012S18_L21AS.pdf)



