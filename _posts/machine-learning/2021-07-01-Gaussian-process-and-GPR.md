---
title: "Gaussian Process & Gaussian Process Regression"
layout: post
use_math: true
tags: ["Machine Learning"]
---

### ì„œë¡ 

"Machine Learning"ì„ ê³µë¶€í•˜ë©´ì„œ ê°œì¸ì ì¸ ìš©ë„ë¡œ ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- [Gaussian Process](#gaussian-process)
- [Gaussian Process Regression](#gaussian-process-regression)

<hr/>

### Gaussian Process

í¬ìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ê¸°ì— ì•ì„œ \<Gaussian Distribution\>ì— ëŒ€í•´ ë³µìŠµí•´ë³´ì.

**1\. 1D Gaussian Distribution**

$$
f(x) = \frac{1}{\sqrt{2\pi} \sigma} \exp \left( - \frac{(x-\mu)^2}{2\sigma^2}\right)
$$

**2\. 2D Gaussian Distribution**

$$
f(\mathbf{x}) = \frac{1}{2\pi \left| \Sigma \right|^{1/2}} \exp \left( - \frac{1}{2} (\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu) \right)
$$

**3\. Multi-variate Gaussian Distribution**

Distribution over random vectors!

$$
f(\mathbf{x}) = \frac{1}{(2\pi)^{n/2} \left| \Sigma \right|^{1/2}} \exp \left( - \frac{1}{2} (\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu) \right)
$$

ì´ì œ \<Gaussian Process\>ì˜ ì •ì˜ë¥¼ ì‚´í´ë³´ì.

<div class="definition" markdown="1">

<span class="statement-title">Definition.</span> Gaussian Process<br>

A sequence of Gaussian distributions! \<**Gaussian Process**\> is a generlization of multi-variate Gaussian distribution. It is a distribution over functions!

$$
\mathcal{GP} (m(x), k(x, x'))
$$

- distribution over functions
  - mean function $m(x)$
  - covariance function $k(x, x')$
- "Every finite subset of RVs in GP is a joint gaussian distribution!"

</div>

ì´ì „ì˜ \<Bernoulli Process\>ì˜ ê²½ìš°, ê° trialì—ì„œ ëª¨ë‘ ë™ì¼í•œ \<Bernoulli Distribution\>ì„ ê°€ì •í–ˆëŠ”ë°, \<Gaussian Process\>ì˜ ê²½ìš° ê° trialì˜ í‰ê· ê³¼ ë¶„ì‚°ì´ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤ëŠ” ì ì— ì£¼ëª©í•˜ì!

<hr/>

### Gaussian Process Regression

<div class="img-wrapper">
  <img src="https://lh3.googleusercontent.com/-QSlMIVtiVFU/X7SgGoqKYwI/AAAAAAAAOOo/u8vbYa-QeVUW5ppkpHQPQ4hV_CH0vF33wCLcBGAsYHQ/w514-h360/image.png" width="500px">
</div>

ì•ì—ì„œ ì‚´í´ë³¸ \<Gaussian Process\>ë¥¼ í™œìš©í•˜ë©´, non-parameteric regressionì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤! ğŸ˜ "í†µê³„ì  ë°ì´í„°ë§ˆì´ë‹(IMEN472)"ì—ì„œ [non-parameteric model](https://bluehorn07.github.io/computer_science/2021/02/24/statistical-data-mining.html#non-parametric-method)ì— ëŒ€í•´ ë‹¤ë£¨ê¸´ í–ˆëŠ”ë°, \<GP Regression; Gaussian Process Regression\>ì— ëŒ€í•´ì„œëŠ” ë‹¤ë£¨ì§€ ì•Šì•˜ë‹¤.

\<GP Regression\>ì€ ì˜ˆì¸¡í•  regression function $f(x)$ë¥¼ GPë¡œ ê°€ì •í•´ ëª¨ë¸ì„ ë§Œë“¤ê¸° ë–„ë¬¸ì— mean function $\mu(x)$ì™€ variance function $\sigma(x)^2$ë¥¼ ì–»ëŠ”ë‹¤. ìœ„ì˜ ê·¸ë¦¼ì€ regression function $\mathcal{GP}(\mu(x), \sigma(x)^2)$ì„ ë°”íƒ•ìœ¼ë¡œ regressionì˜ **ì‹ ë¢°êµ¬ê°„(confidence level)**ì„ ìœ ë„í•œ ê²ƒì´ë‹¤. regressionì˜ ì‹ ë¢°êµ¬ê°„ì„ ì–»ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì€ \<GP Regression\>ì˜ ì¥ì  ì¤‘ í•˜ë‚˜ë‹¤! ğŸ‘

<br/>

ë°ì´í„°ì…‹ $\mathcal{D} = \\{ (x_i, y_i)^n_{i=1}\\} = (X, y)$ì— ëŒ€í•´ GP regressionì€ ì•„ë˜ì™€ ê°™ì´ ëª¨ë¸ë§í•œë‹¤.

$$
\begin{aligned}
y_i &= f(x_i) + \epsilon_i \\
f &\sim \mathcal{GP}(\cdot \mid 0, K) \\
\epsilon_i &\sim N(\cdot \mid 0, \sigma^2)
\end{aligned}
$$

ì´ë•Œ, ë‘ ë²ˆì§¸ ì¤„ì˜ $f \sim \mathcal{GP}(\cdot \mid 0, K)$ê°€ ëˆˆì— ëˆë‹¤. í•¨ìˆ˜ $f$ê°€ GPì˜ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤... ì´ê²Œ ë¬´ìŠ¨ ë§ì¼ê¹Œ? ì´ê±¸ ì´í•´í•˜ë ¤ë©´ \<distribution over functions\>ì— ëŒ€í•´ ë¨¼ì € ì´í•´í•´ì•¼ í•œë‹¤.

<div class="definition" markdown="1">

<span class="statement-title">Definition.</span> Distribution over functions<br>

\<Distribution over functions\>ì— ëŒ€í•œ ê°œë…ì€ ìš°ë¦¬ê°€ ê¸°ì¡´ì— ì•Œë˜ distributionì˜ ê°œë…ë³´ë‹¤ ì¢€ë” ì¶”ìƒì ì¸ ì˜ì—­ì— ìˆë‹¤. ë¨¼ì € í•¨ìˆ˜(function)ì„ ëª¨ì€ ì–´ë–¤ set ë˜ëŠ” spaceê°€ ìˆë‹¤ê³  ìƒê°í•˜ì. ì´ space of functionì€ $\mathbb{R}^2$ë‚˜ $\mathbb{R}^n$ì™€ ê°™ì´ í‘œí˜„ë˜ëŠ” ê·¸ëŸ° ê³µê°„ì€ ì•„ë‹ˆë‹¤. ë‹¨ìˆœíˆ big collection of functionsë¼ê³  ìƒê°í•˜ëŠ” ê²ƒì´ ë” ì ì ˆí•˜ë‹¤. 

ìš°ë¦¬ëŠ” ì´ space of function ìœ„ì—ì„œ í™•ë¥ ì„ ì •ì˜í•  ê²ƒì´ë‹¤. space of functionì€ ì—°ì†ì ì¸ ê³µê°„ì´ê¸° ë•Œë¬¸ì—[^1] ì—¬ê¸°ì„œì˜ distributionì€ subset of functionsë¥¼ ê·¸ë¦´ í™•ë¥ ì„ ë§í•œë‹¤. $(x, y)$ì˜ ìŒìœ¼ë¡œ ëœ ë°ì´í„°ì…‹ $D$ë¥¼ ìƒê°í•´ë³´ì. ìš°ë¦¬ëŠ” (random) functionì˜ ì§‘í•©ì´ ì´ $\\{ (x, y) \\}$ì˜ ë°ì´í„°ì…‹ì„ ì§€ë‚˜ëŠ” í™•ë¥ ì„ êµ¬í•˜ê³ ì í•œë‹¤.

</div>

<br/>


ì „í†µì ì¸ Parameteric Regressionì—ì„œëŠ” ìƒ˜í”Œ ë°ì´í„° $X$ì— LS methodì™€ ê°™ì€ ìµœì í™”ë¥¼ í†µí•´ parameter $\Theta$ì— ëŒ€í•œ ìµœì í•´ $\theta$ë¥¼ ìœ ë„í–ˆë‹¤. ì´ ìµœì í™” ê³¼ì •ì€ $p(\theta \mid X)$, ì¦‰ ì£¼ì–´ì§„ ë°ì´í„° $X$ì— ëŒ€í•œ posterior probabilityê°€ ìµœëŒ€ì¸ $\theta$ë¥¼ êµ¬í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.

ë°˜ë©´ì— \<GP Regression\>ì€ parameter $\Theta$ë¥¼ <span class="half_HL">probabilistically distributed value</span>ì¸ RVë¡œ ì·¨ê¸‰í•œë‹¤. Parameteric Regressionì—ì„œ $\Theta$ë¥¼ deterministic valueë¡œ ì·¨ê¸‰í•œ ê²ƒê³¼ëŠ” ëŒ€ì¡°ëœë‹¤. $\Theta$ê°€ RVê°€ ë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ì— ëŒ€ì‘í•˜ëŠ” í™•ë¥ ë¶„í¬ $p(\theta)$ë„ ì¡´ì¬í•œë‹¤.

$$
Y = f(X) + \epsilon
$$

ì´ì œ ëª¨ë¸ì˜ parameter $\Theta$ê°€ RVê°€ ë˜ì—ˆê¸° ë•Œë¬¸ì— regression model $f(X)$ì—­ì‹œ RVê°€ ë˜ë©°, ì–´ë–¤ í™•ë¥  ë¶„í¬ë¥¼ ê°–ê²Œ ëœë‹¤. ì´ê²ƒì„ $p(f \mid X)$ë¼ê³  í•˜ì.

ì´ë•Œ, $p(f \mid X)$ëŠ” í•¨ìˆ˜ì— ëŒ€í•œ ë¶„í¬, functional distributionì´ê¸° ë•Œë¬¸ì— ìœ ë„í•˜ëŠ” ê²ƒì´ ì‰½ì§€ ì•Šë‹¤. ê·¸ëŸ°ë°, <span class="half_HL">\<GP Regression\>ì—ì„œëŠ” regression model $f$ê°€ \<Gaussian Process\>ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•œë‹¤!!</span>

$$
p(f) = f(X) \sim \mathcal{GP} \left( \mu(x), k(x, x_i) \right)
$$

ì´ë•Œ, mean function, variance functionì€ ì•„ë˜ì™€ ê°™ë‹¤.

- $\mu(x) = E [f(x)]$
- $k(x, x') = E \left[(f(x) - \mu(x)) (f(x') - \mu(x')) \right] = \sigma_f^2 \exp \left( - \dfrac{1}{2 L^2} (x - x')^2 \right)$

<br/>

ì´ë•Œ $k(x, x')$ëŠ” \<squared exponential kernel\>ì´ë‹¤. hyper-parameterë¡œ $\sigma_f$, $L$ê°€ ìˆëŠ”ë°,

- $\sigma_f$: similarityì˜ í¬ê¸°ë¥¼ ì¡°ì ˆ
- $L$: similairty ë¶„í¬ì˜ í­ë¥¼ ì¡°ì ˆ

$\sigma_f$ì™€ $L$ëŠ” \<GP Regression\>ì˜ hyper-parameterë¡œ ì´ ê°’ì„ ì¡°ì •í•´ ëª¨ë¸ì˜ bais, varianceê°€ ë‹¬ë¼ì§„ë‹¤.

- $L$ ê°’ì´ ì‘ì„ìˆ˜ë¡ ê°€ê¹Œì´ ìˆëŠ” ìƒ˜í”Œì„ ì£¼ë¡œ ë³¸ë‹¤. ê·¸ë˜ì„œ modelì˜ fluctuationì´ ì‹¬í•´ì§„ë‹¤.
  - ê·¹ë‹¨ì ìœ¼ë¡œëŠ” ì œì¼ ê°€ê¹Œì´ ìˆëŠ” 1 ë˜ëŠ” 2ê°œ ìƒ˜í”Œë§Œ ë³´ëŠ” ê²½ìš°ë¥¼ ìƒê°í•´ë³´ë©´ ëœë‹¤.
- ë°˜ëŒ€ë¡œ $L$ ê°’ì´ ì»¤ì§€ë©´, ë©€ë¦¬ ìˆëŠ” ìƒ˜í”Œë„ ë°˜ì˜í•˜ê¸° ë•Œë¬¸ì— modelì´ smooth í•´ì§„ë‹¤.
- ì•„ë˜ ê·¸ë¦¼ì˜ ì²«ë²ˆì§¸ ì¤„ì˜ ê²½ìš°ë¥¼ ì‚´í´ë³´ë¼.


- $\sigma_f$ê°€ í´ìˆ˜ë¡ similarityì˜ ê°’ ìì²´ë¥¼ ë†’ê²Œ ì¸¡ì •í•˜ê¸° ë•Œë¬¸ì—, ìì—°ìŠ¤ëŸ½ê²Œ modelì˜  variance ê°’ì´ ì»¤ì§€ê²Œ ëœë‹¤.
- ì•„ë˜ ê·¸ë¦¼ì˜ ë‘ë²ˆì§¸ ì¤„ì˜ ê²½ìš°ë¥¼ ì‚´í´ë³´ë¼. uncertaintyê°€ ì¡´ì¬í•˜ëŠ” êµ¬ì—­ì€ ë§¤ìš° í° uncertaintyë¥¼ ê°–ëŠ”ë‹¤.

<div class="img-wrapper">
  <img src="https://lh3.googleusercontent.com/-3stFRMVzKRY/X7vwBqAi6GI/AAAAAAAAOxo/pD_ZWUZQ8bg_wk1hnP8QvhMbE-W1cld5QCLcBGAsYHQ/w627-h633/image.png" width="600px">
</div>

<br/>

\<GP Regression\>ì—ì„œëŠ” mean function $\mu(x)$ë¥¼ ì˜ˆì¸¡ í•¨ìˆ˜ë¡œ ì‚¬ìš©í•˜ê³ , ë˜ variance function $k(x, x')$ë¥¼ í†µí•´ ì˜ˆì¸¡ê°’ì˜ ì‹ ë¢°êµ¬ê°„ì„ êµ¬í•œë‹¤.

(ì‚¬ì‹¤ \<GP Regression\>ì„ ì œëŒ€ë¡œ ì´í•´í•˜ë ¤ë©´, ì¢€ë” ìˆ˜í•™ì ì¸ ë‚´ìš©ê³¼ í…Œí¬ë‹‰ì„ ì‚´í´ë´ì•¼ í•œë‹¤. ì§€ê¸ˆì€ ì‹œê°„ì´ ì—†ì–´ ì´ ì •ë„ë¡œë§Œ ì •ë¦¬í•˜ê³  ë„˜ì–´ê°€ê² ë‹¤ ğŸ˜¥)

<hr/>

ì–´ë–»ê²Œ ë³´ë©´, ë‹¤ë¥¸ non-parametric methodì¸ \<KDE; Kernel Density Distribution\>ê³¼ë„ ë¹„ìŠ·í•œ ë©´ì´ ìˆê³ , \<KNN\> ê¸°ë°˜ì˜ [\<Nadaraya-Watson Estimator\>](https://bluehorn07.github.io/computer_science/2021/05/16/KNN-and-kernel-method.html#nadaraya-watson-estimator)ì™€ë„ ë¹„ìŠ·í•œ ë©´ì´ ìˆëŠ” ê²ƒ ê°™ë‹¤. (ì…‹ë‹¤ kernel methodë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤.) ê·¸ë˜ë„ \<GP Regression\>ì€ 

- "directly estimate regression function"
- "can report confidence level using variance function"

ë¼ëŠ” ì ì—ì„œ ë‘ non-parametric ë°©ë²•ê³¼ëŠ” ì°¨ì´ê°€ ìˆëŠ” ê²ƒ ê°™ë‹¤.

<hr/>

### references

- ['ì†ì“°'ë‹˜ì˜ í¬ìŠ¤íŠ¸](https://sonsnotation.blogspot.com/2020/11/11-2-gaussian-progress-regression.html)

<hr/>

[^1]: space of functionì´ continuous domainì´ë¼ê³  ëª…ì‹œì ìœ¼ë¡œ ë§í•˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ ì•”íŠ¼ ê·¸ë ‡ë‹¤.